{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49121ca",
   "metadata": {},
   "source": [
    "119个类别:0-118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447478d",
   "metadata": {},
   "source": [
    "# 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9de3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import json\n",
    "\n",
    "with open('trains.json', 'r',encoding='utf-8') as f:\n",
    "    trains = json.load(f)\n",
    "    \n",
    "trains_data = [] #[[第一个句子的分词结果],[第二个句子的分词结果],...]\n",
    "for sent in trains:\n",
    "    fenci = jieba.cut(sent['sentence'],cut_all=False)\n",
    "    res=[]\n",
    "    for j in fenci:\n",
    "        res.append(j)\n",
    "    trains_data.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24760f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(trains_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa70d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tests.json', 'r',encoding='utf-8') as f:\n",
    "    tests = json.load(f)\n",
    "    \n",
    "tests_data = [] #[[第一个句子的分词结果],[第二个句子的分词结果],...]\n",
    "for sent in tests:\n",
    "    fenci = jieba.cut(sent['sentence'],cut_all=False)\n",
    "    res=[]\n",
    "    for j in fenci:\n",
    "        res.append(j)\n",
    "    tests_data.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bde31b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1425\n"
     ]
    }
   ],
   "source": [
    "print(len(tests_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24d8a5",
   "metadata": {},
   "source": [
    "# 建立词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cd9710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fedf7007",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Vocab.build(trains_data+tests_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "131321a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75040"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.token_to_idx) #词表的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb1134cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sent in enumerate(trains):\n",
    "    train_data[i] = (vocab.convert_tokens_to_ids(trains_data[i]), int(sent['label']))\n",
    "    \n",
    "for i,sent in enumerate(tests):\n",
    "    test_data[i] = (vocab.convert_tokens_to_ids(tests_data[i]), int(sent['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9b75c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2, 3, 13, 14, 15, 16, 17, 18, 19, 5, 6, 7, 20, 21, 22, 23, 24, 25, 26, 13, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 13, 38, 39, 40, 41, 42, 11, 43, 44, 45, 46, 47, 48, 49, 12, 50, 51, 52, 13, 53, 35, 50, 54, 55, 56, 57, 58, 12, 7, 20, 22, 40, 59, 12, 60, 47, 61, 62, 59, 63, 64, 65, 66, 13, 67, 47, 68, 69, 70, 71, 22, 72, 50, 35, 47, 49, 73, 13, 11, 74, 75, 15, 40, 65, 76, 40, 65, 77, 40, 58, 78, 49, 79, 13, 80, 81, 39, 82, 77, 83, 22, 84, 85, 86, 13, 11, 87, 88, 89, 90, 91, 92, 93, 3, 22, 94, 40, 95, 96, 97, 98, 12, 99, 22, 50, 49, 13, 100, 29, 44, 101, 102, 90, 103, 104, 50, 35, 4, 7, 53, 35, 54, 55, 7, 20, 51, 105, 106, 107, 13, 108, 109, 40, 110, 111, 112, 49, 79, 15, 40, 65, 76, 40, 65, 113, 40, 114, 115, 49, 79, 116, 117, 41, 118, 13, 11, 119, 120, 4, 15, 121, 119, 122, 15, 123, 124, 11, 13, 125, 126, 121, 127, 13, 128, 82, 7, 20, 62, 129, 130, 131, 132, 133, 12, 119, 39, 62, 13, 129, 13, 134, 135, 63, 136, 62, 13, 61, 59, 137, 138, 139, 140, 141, 140, 142, 63, 143, 144, 11, 145, 146, 147, 148, 149, 141, 140, 142, 150, 34, 35, 36, 37, 13, 38, 39, 40, 41, 151, 150, 152, 65, 153, 154, 155, 156, 157, 103, 158, 159, 65, 51, 160, 153, 161], 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede08cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run utils.py\n",
    "# train_data, test_data, vocab = load_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805159da",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9b5b7",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "847f0085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff6cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BowDataset(Dataset):\n",
    "    def __init__(self, data): #data为原始的数据\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002ef52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ASUS\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.151 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "%run utils.py\n",
    "train_data, test_data, vocab = load_sentence()\n",
    "train_dataset = BowDataset(train_data) #BowDataset是Dataset的子类\n",
    "test_dataset = BowDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3656d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    # 从独立样本集合中构建各批次的输入输出\n",
    "    # 其中，BowDatasete类定义了一个样本的数据结构，即输入标签和输出标签的元组\n",
    "    # 因此，将输入inputs定义为一个张量的列表，其中每个张量为原始句子中标记序列对应的索引值序列ex[0]\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    # 输出目标targets为该批次中全部样例输出结果（0或1）构成的张量\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    offsets = [0] + [i.shape[0] for i in inputs]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)  #获取一个批次中每个序列的偏移量\n",
    "    inputs = torch.cat(inputs)\n",
    "    return inputs, offsets, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d3cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa9d0a",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc110e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.activate = F.relu\n",
    "        self.linear2 = nn.Linear(hidden_dim, num_class)\n",
    "    def forward(self, inputs, offsets):\n",
    "        embedding = self.embedding(inputs, offsets)\n",
    "        hidden = self.activate(self.linear1(embedding))\n",
    "        outputs = self.linear2(hidden)\n",
    "        log_probs = F.log_softmax(outputs, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4de6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embedding): EmbeddingBag(75040, 128, mode=mean)\n",
       "  (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=119, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import *\n",
    "\n",
    "# 超参数设置\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 119\n",
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "\n",
    "# 加载模型\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) # 将模型加载到CPU或GPU设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf99f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:26<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1163.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:35<00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 880.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:35<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 703.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:27<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 575.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:43<00:00,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 473.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "        #inputs, offsets, targets = [x for x in batch]\n",
    "        log_probs = model(inputs, offsets)\n",
    "        #print(log_probs)\n",
    "        #print(targets)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a9c02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -8.0517,  -7.6918,  -9.6376, -12.5522, -10.2860, -12.0264,  -8.7566,\n",
      "         -9.3070,  -7.8767, -12.3592,  -9.0817,  -6.9064,  -4.5602,  -5.8522,\n",
      "         -4.5247,  -3.0474,  -2.6779,  -1.1587,  -2.5605,  -3.2101,  -3.9668,\n",
      "         -1.9375,  -2.9541,  -3.7549,  -3.4093,  -5.6807,  -5.5112,  -9.8248,\n",
      "         -5.2909,  -9.0394,  -5.8839,  -5.0888,  -8.9975,  -7.6307,  -8.7728,\n",
      "         -7.0418,  -6.7274,  -7.7742,  -7.7314,  -9.2883,  -7.3273,  -7.7563,\n",
      "         -7.8095,  -8.6988, -12.0333, -10.9629,  -5.2116,  -7.3419,  -4.1284,\n",
      "         -7.1459,  -6.5449,  -6.0579,  -7.6438,  -6.7750, -11.4560, -13.4348,\n",
      "         -6.5093, -10.1721,  -9.8150,  -9.3458,  -5.5952,  -6.6343,  -6.2018,\n",
      "         -8.3270,  -9.9610,  -9.4331, -10.7196,  -8.4938, -11.0040, -12.3751,\n",
      "         -3.5197,  -4.1683,  -9.9634,  -9.3772, -14.4457, -12.6528, -14.1032,\n",
      "        -15.8057, -10.1047, -15.6893, -12.8838,  -8.3270,  -7.8649, -15.8762,\n",
      "         -8.7953, -12.5397,  -7.4767,  -7.5716,  -6.4801,  -9.7550,  -8.6567,\n",
      "         -5.9488, -13.4844, -16.6461, -15.8814, -12.8336, -13.2803,  -8.5125,\n",
      "         -6.8785, -12.3718,  -6.0017,  -7.5788,  -4.9845,  -6.3230,  -4.1638,\n",
      "        -11.4308, -11.4758, -10.5596, -10.5511,  -8.4372, -10.7215, -12.4750,\n",
      "         -7.8511,  -9.1243,  -8.9370,  -7.8297, -10.9311, -16.1372,  -4.8542],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(log_probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1176ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 17,  88,  16,  70,  97, 111,  95,  70,  78,  21,   4,  13,  46, 118,\n",
      "         13,  49], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "043155a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1425/1425 [00:01<00:00, 974.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试过程\n",
    "acc = 0\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "    #inputs, offsets, targets = [x for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, offsets)\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "# 输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc5f47",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1866f",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff0143ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e497035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "236add1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "#%run utils.py\n",
    "#train_data, test_data, vocab = load_sentence() #MLP模型已经运行过了\n",
    "train_dataset = CnnDataset(train_data)\n",
    "test_dataset = CnnDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da480c65",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9a2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm是一个Pyth模块，能以进度条的方式显示迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#超参数设置\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 119\n",
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "filter_size = 3\n",
    "num_filter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7781957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, filter_size, num_filter, num_class):\n",
    "        super(CNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1d = nn.Conv1d(embedding_dim, num_filter, filter_size, padding=1)\n",
    "        self.activate = F.relu\n",
    "        self.linear = nn.Linear(num_filter, num_class)\n",
    "    def forward(self, inputs):\n",
    "        embedding = self.embedding(inputs)\n",
    "        convolution = self.activate(self.conv1d(embedding.permute(0, 2, 1))) #permute维度交换\n",
    "        pooling = F.max_pool1d(convolution, kernel_size=convolution.shape[2])\n",
    "        outputs = self.linear(pooling.squeeze(dim=2))\n",
    "        log_probs = F.log_softmax(outputs, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3b3aa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(75040, 128)\n",
       "  (conv1d): Conv1d(128, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (linear): Linear(in_features=100, out_features=119, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(len(vocab), embedding_dim, filter_size, num_filter, num_class)\n",
    "model.to(device) #将模型加载到CPU或GPU设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53fff6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:45<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1159.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:35<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 904.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:31<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 736.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:31<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 598.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:31<00:00, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 471.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, targets = [x.to(device) for x in batch]\n",
    "        #inputs, targets = [x for x in batch]\n",
    "        log_probs = model(inputs)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "146dca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1425/1425 [00:02<00:00, 579.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#测试过程\n",
    "import numpy as np\n",
    "acc = 0\n",
    "y_pred = np.array([]).astype(int)  #存储真实的target\n",
    "y_true = np.array([]).astype(int)  #存储预测出来的target\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, targets = [x.to(device) for x in batch]\n",
    "    #inputs, targets = [x for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs)\n",
    "        y_pred = np.append(y_pred,output.argmax(dim=1).cpu().numpy()) #要先把数据放在cpu上，才能转成numpy\n",
    "        y_true = np.append(y_true,targets.cpu().numpy())\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "#输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56c25f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbb767c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18784838652529542"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。\n",
    "# 该方法能够平等看待每个类别，但是它的值会受稀有类别影响。\n",
    "f1_score(y_true,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6f9cc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40249235248216314"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。\n",
    "# 该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。\n",
    "f1_score(y_true,y_pred,average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35603b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4357894736842105"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。\n",
    "f1_score(y_true,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc35a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b02f4c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.hist(y_true,bins=119)\n",
    "plt.show() #可以看到类别分布很不均匀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b869147",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a431ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence\n",
    "\n",
    "#tqdm是一个Python模块，能以进度条的方式显式迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class LstmDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    # 获得每个序列的长度\n",
    "    lengths = torch.tensor([len(ex[0]) for ex in examples])\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, lengths, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e2be8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#加载数据\n",
    "\n",
    "train_data, test_data, vocab = load_sentence()\n",
    "train_dataset = LstmDataset(train_data)\n",
    "test_dataset = LstmDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a85ecbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        embeddings = self.embeddings(inputs)\n",
    "        # pack_padded_sequence函数将变长序列打包\n",
    "        # lengths.cpu()注意这里改为cpu，pytorch自身的问题\n",
    "        x_pack = pack_padded_sequence(embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        hidden, (hn, cn) = self.lstm(x_pack)\n",
    "        outputs = self.output(hn[-1])\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7877866",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LSTM(\u001b[38;5;28mlen\u001b[39m(vocab), embedding_dim, hidden_dim, num_class)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#将模型加载到GPU中\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#训练过程\u001b[39;00m\n\u001b[0;32m      7\u001b[0m nll_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:612\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:359\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 359\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    370\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:381\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 381\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:610\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "#加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) #将模型加载到GPU中\n",
    "\n",
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "        log_probs = model(inputs, lengths)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f93b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试过程\n",
    "acc = 0\n",
    "y_pred = np.array([]).astype(int)  #存储真实的target\n",
    "y_true = np.array([]).astype(int)  #存储预测出来的target\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, lengths)\n",
    "        y_pred = np.append(y_pred,output.argmax(dim=1).cpu().numpy()) #要先把数据放在cpu上，才能转成numpy\n",
    "        y_true = np.append(y_true,targets.cpu().numpy())\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "#输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")\n",
    "print(f\"f1_macro:{f1_score(y_true,y_pred,average='macro'):.2f}\")\n",
    "print(f\"f1_weighted:{f1_score(y_true,y_pred,average='weighted'):.2f}\")\n",
    "print(f\"f1_macro:{f1_score(y_true,y_pred,average='macro'):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.7.1",
   "language": "python",
   "name": "pytorch1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
