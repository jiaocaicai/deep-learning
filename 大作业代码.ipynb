{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e177fdc",
   "metadata": {},
   "source": [
    "# 查看数据情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1aee2950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别：[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118]\n",
      "训练集的数据量：10000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuCUlEQVR4nO3df3hU5Z3//1dCSILATAhsZpg1wWwvV0ApKsE4gn5qyUXQiCJpLZpits0lW5ugEIskq1B/B6L1BxhJ8XINu+JqvVaoxIrGIGStIYRgigJGuqUEpZO0GzNDYkkCOd8//HIuB1AITJjcyfNxXee6POe+z5z3uc3MvLjnzJkIy7IsAQAAGCQy3AUAAAD0FAEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCcqHAX0Fu6u7t18OBBDR8+XBEREeEuBwAAnAbLsnTo0CF5PB5FRn7zPEu/DTAHDx5UYmJiuMsAAABn4MCBAzr//PO/sb3fBpjhw4dL+moAHA5HmKsBAACnIxAIKDEx0X4f/yb9NsAc+9jI4XAQYAAAMMypLv/gIl4AAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA40SFuwAA6I8uKHgzaP3PyzLCVAnQPzEDAwAAjNPjAFNVVaWZM2fK4/EoIiJC69evP6HPnj17dOONN8rpdGro0KGaPHmyGhsb7fbDhw8rNzdXI0eO1LBhw5SZmammpqagx2hsbFRGRobOO+88JSQkaNGiRTpy5EjPzxAAAPQ7PQ4w7e3tmjhxokpKSk7a/r//+7+aOnWqxo4dq82bN2vnzp1asmSJYmNj7T4LFy7Uhg0b9Nprr2nLli06ePCgZs+ebbcfPXpUGRkZ6uzs1AcffKA1a9aorKxMS5cuPYNTBAAA/U2EZVnWGe8cEaF169Zp1qxZ9rY5c+Zo8ODB+s///M+T7uP3+/UP//APevnll/WDH/xAkvTJJ59o3Lhxqq6u1pVXXqm33npLN9xwgw4ePCiXyyVJKi0t1eLFi/XXv/5V0dHRp6wtEAjI6XTK7/fL4XCc6SkCwBnhGhjgzJzu+3dIr4Hp7u7Wm2++qX/+539Wenq6EhISlJqaGvQxU11dnbq6upSWlmZvGzt2rJKSklRdXS1Jqq6u1oQJE+zwIknp6ekKBALatWvXSY/d0dGhQCAQtAAAgP4ppAGmublZbW1tWrZsmWbMmKF33nlHN998s2bPnq0tW7ZIknw+n6KjoxUXFxe0r8vlks/ns/t8Pbwcaz/WdjJFRUVyOp32kpiYGMpTAwAAfUjIZ2Ak6aabbtLChQt16aWXqqCgQDfccINKS0tDeagTFBYWyu/328uBAwd69XgAACB8QhpgRo0apaioKI0fPz5o+7hx4+xvIbndbnV2dqq1tTWoT1NTk9xut93n+G8lHVs/1ud4MTExcjgcQQsAAOifQhpgoqOjNXnyZDU0NARt//TTTzVmzBhJ0qRJkzR48GBVVlba7Q0NDWpsbJTX65Ukeb1effTRR2pubrb7VFRUyOFwnBCOAADAwNPjO/G2tbXpj3/8o72+b98+1dfXKz4+XklJSVq0aJF+9KMf6ZprrtG1116rjRs3asOGDdq8ebMkyel0KicnR/n5+YqPj5fD4dD8+fPl9Xp15ZVXSpKmT5+u8ePHa+7cuSouLpbP59P999+v3NxcxcTEhObMAQCAsXocYLZv365rr73WXs/Pz5ckZWdnq6ysTDfffLNKS0tVVFSku+66SxdddJH++7//W1OnTrX3eeqppxQZGanMzEx1dHQoPT1dzz33nN0+aNAglZeX684775TX69XQoUOVnZ2thx566GzOFQAA9BNndR+Yvoz7wAAIJ+4DA5yZsNwHBgAA4FwgwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjNPjAFNVVaWZM2fK4/EoIiJC69ev/8a+P/vZzxQREaGnn346aHtLS4uysrLkcDgUFxennJwctbW1BfXZuXOnrr76asXGxioxMVHFxcU9LRUAAPRTPQ4w7e3tmjhxokpKSr6137p167R161Z5PJ4T2rKysrRr1y5VVFSovLxcVVVVmjdvnt0eCAQ0ffp0jRkzRnV1dXr88cf1wAMPaPXq1T0tFwAA9ENRPd3huuuu03XXXfetfT7//HPNnz9fb7/9tjIyMoLa9uzZo40bN6q2tlYpKSmSpJUrV+r666/XE088IY/Ho7Vr16qzs1P//u//rujoaF188cWqr6/Xk08+GRR0AADAwBTya2C6u7s1d+5cLVq0SBdffPEJ7dXV1YqLi7PDiySlpaUpMjJSNTU1dp9rrrlG0dHRdp/09HQ1NDToiy++OOlxOzo6FAgEghYAANA/hTzALF++XFFRUbrrrrtO2u7z+ZSQkBC0LSoqSvHx8fL5fHYfl8sV1OfY+rE+xysqKpLT6bSXxMTEsz0VAADQR4U0wNTV1emZZ55RWVmZIiIiQvnQp1RYWCi/328vBw4cOKfHBwAA505IA8z//M//qLm5WUlJSYqKilJUVJT279+ve+65RxdccIEkye12q7m5OWi/I0eOqKWlRW632+7T1NQU1OfY+rE+x4uJiZHD4QhaAABA/xTSADN37lzt3LlT9fX19uLxeLRo0SK9/fbbkiSv16vW1lbV1dXZ+23atEnd3d1KTU21+1RVVamrq8vuU1FRoYsuukgjRowIZckAAMBAPf4WUltbm/74xz/a6/v27VN9fb3i4+OVlJSkkSNHBvUfPHiw3G63LrroIknSuHHjNGPGDN1xxx0qLS1VV1eX8vLyNGfOHPsr17fddpsefPBB5eTkaPHixfr444/1zDPP6KmnnjqbcwUAAP1EjwPM9u3bde2119rr+fn5kqTs7GyVlZWd1mOsXbtWeXl5mjZtmiIjI5WZmakVK1bY7U6nU++8845yc3M1adIkjRo1SkuXLuUr1AAAQJIUYVmWFe4iekMgEJDT6ZTf7+d6GADn3AUFbwat/3lZxjf0BPB1p/v+zW8hAQAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADG6XGAqaqq0syZM+XxeBQREaH169fbbV1dXVq8eLEmTJigoUOHyuPx6Pbbb9fBgweDHqOlpUVZWVlyOByKi4tTTk6O2tragvrs3LlTV199tWJjY5WYmKji4uIzO0MAANDv9DjAtLe3a+LEiSopKTmh7csvv9SOHTu0ZMkS7dixQ6+//roaGhp04403BvXLysrSrl27VFFRofLyclVVVWnevHl2eyAQ0PTp0zVmzBjV1dXp8ccf1wMPPKDVq1efwSkCAID+JsKyLOuMd46I0Lp16zRr1qxv7FNbW6srrrhC+/fvV1JSkvbs2aPx48ertrZWKSkpkqSNGzfq+uuv12effSaPx6NVq1bpvvvuk8/nU3R0tCSpoKBA69ev1yeffHJatQUCATmdTvn9fjkcjjM9RQA4IxcUvBm0/udlGWGqBDDL6b5/9/o1MH6/XxEREYqLi5MkVVdXKy4uzg4vkpSWlqbIyEjV1NTYfa655ho7vEhSenq6Ghoa9MUXX/R2yQAAoI+L6s0HP3z4sBYvXqxbb73VTlE+n08JCQnBRURFKT4+Xj6fz+6TnJwc1MflctltI0aMOOFYHR0d6ujosNcDgUBIzwUAAPQdvTYD09XVpVtuuUWWZWnVqlW9dRhbUVGRnE6nvSQmJvb6MQEAQHj0SoA5Fl7279+vioqKoM+w3G63mpubg/ofOXJELS0tcrvddp+mpqagPsfWj/U5XmFhofx+v70cOHAglKcEAAD6kJAHmGPhZe/evXr33Xc1cuTIoHav16vW1lbV1dXZ2zZt2qTu7m6lpqbafaqqqtTV1WX3qaio0EUXXXTSj48kKSYmRg6HI2gBAAD9U48DTFtbm+rr61VfXy9J2rdvn+rr69XY2Kiuri794Ac/0Pbt27V27VodPXpUPp9PPp9PnZ2dkqRx48ZpxowZuuOOO7Rt2zb9/ve/V15enubMmSOPxyNJuu222xQdHa2cnBzt2rVLr776qp555hnl5+eH7swBAICxevw16s2bN+vaa689YXt2drYeeOCBEy6+Pea9997T9773PUlf3cguLy9PGzZsUGRkpDIzM7VixQoNGzbM7r9z507l5uaqtrZWo0aN0vz587V48eLTrpOvUQMIJ75GDZyZ033/Pqv7wPRlBBgA4USAAc5Mn7kPDAAAQKgRYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4/Q4wFRVVWnmzJnyeDyKiIjQ+vXrg9oty9LSpUs1evRoDRkyRGlpadq7d29Qn5aWFmVlZcnhcCguLk45OTlqa2sL6rNz505dffXVio2NVWJiooqLi3t+dgAAoF/qcYBpb2/XxIkTVVJSctL24uJirVixQqWlpaqpqdHQoUOVnp6uw4cP232ysrK0a9cuVVRUqLy8XFVVVZo3b57dHggENH36dI0ZM0Z1dXV6/PHH9cADD2j16tVncIoAAKC/ibAsyzrjnSMitG7dOs2aNUvSV7MvHo9H99xzj37xi19Ikvx+v1wul8rKyjRnzhzt2bNH48ePV21trVJSUiRJGzdu1PXXX6/PPvtMHo9Hq1at0n333Sefz6fo6GhJUkFBgdavX69PPvnktGoLBAJyOp3y+/1yOBxneooAcEYuKHgzaP3PyzLCVAlgltN9/w7pNTD79u2Tz+dTWlqavc3pdCo1NVXV1dWSpOrqasXFxdnhRZLS0tIUGRmpmpoau88111xjhxdJSk9PV0NDg7744ouTHrujo0OBQCBoAQAA/VNIA4zP55MkuVyuoO0ul8tu8/l8SkhICGqPiopSfHx8UJ+TPcbXj3G8oqIiOZ1Oe0lMTDz7EwIAAH1Sv/kWUmFhofx+v70cOHAg3CUBAIBeEtIA43a7JUlNTU1B25uamuw2t9ut5ubmoPYjR46opaUlqM/JHuPrxzheTEyMHA5H0AIAAPqnkAaY5ORkud1uVVZW2tsCgYBqamrk9XolSV6vV62traqrq7P7bNq0Sd3d3UpNTbX7VFVVqaury+5TUVGhiy66SCNGjAhlyQAAwEA9DjBtbW2qr69XfX29pK8u3K2vr1djY6MiIiK0YMECPfLII3rjjTf00Ucf6fbbb5fH47G/qTRu3DjNmDFDd9xxh7Zt26bf//73ysvL05w5c+TxeCRJt912m6Kjo5WTk6Ndu3bp1Vdf1TPPPKP8/PyQnTgAADBXVE932L59u6699lp7/VioyM7OVllZme699161t7dr3rx5am1t1dSpU7Vx40bFxsba+6xdu1Z5eXmaNm2aIiMjlZmZqRUrVtjtTqdT77zzjnJzczVp0iSNGjVKS5cuDbpXDAAAGLjO6j4wfRn3gQEQTtwHBjgzYbkPDAAAwLlAgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGCfkAebo0aNasmSJkpOTNWTIEH3nO9/Rww8/LMuy7D6WZWnp0qUaPXq0hgwZorS0NO3duzfocVpaWpSVlSWHw6G4uDjl5OSora0t1OUCAAADhTzALF++XKtWrdKzzz6rPXv2aPny5SouLtbKlSvtPsXFxVqxYoVKS0tVU1OjoUOHKj09XYcPH7b7ZGVladeuXaqoqFB5ebmqqqo0b968UJcLAAAMFGF9fWokBG644Qa5XC698MIL9rbMzEwNGTJEL730kizLksfj0T333KNf/OIXkiS/3y+Xy6WysjLNmTNHe/bs0fjx41VbW6uUlBRJ0saNG3X99dfrs88+k8fjOWUdgUBATqdTfr9fDocjlKcIAKd0QcGbQet/XpYRpkoAs5zu+3fIZ2CuuuoqVVZW6tNPP5Uk/eEPf9D777+v6667TpK0b98++Xw+paWl2fs4nU6lpqaqurpaklRdXa24uDg7vEhSWlqaIiMjVVNTc9LjdnR0KBAIBC3oPRcUvBm0AABwLkWF+gELCgoUCAQ0duxYDRo0SEePHtWjjz6qrKwsSZLP55MkuVyuoP1cLpfd5vP5lJCQEFxoVJTi4+PtPscrKirSgw8+GOrTAQAAfVDIZ2B+85vfaO3atXr55Ze1Y8cOrVmzRk888YTWrFkT6kMFKSwslN/vt5cDBw706vEAAED4hHwGZtGiRSooKNCcOXMkSRMmTND+/ftVVFSk7Oxsud1uSVJTU5NGjx5t79fU1KRLL71UkuR2u9Xc3Bz0uEeOHFFLS4u9//FiYmIUExMT6tMBAAB9UMhnYL788ktFRgY/7KBBg9Td3S1JSk5OltvtVmVlpd0eCARUU1Mjr9crSfJ6vWptbVVdXZ3dZ9OmTeru7lZqamqoSwYAAIYJ+QzMzJkz9eijjyopKUkXX3yxPvzwQz355JP66U9/KkmKiIjQggUL9Mgjj+jCCy9UcnKylixZIo/Ho1mzZkmSxo0bpxkzZuiOO+5QaWmpurq6lJeXpzlz5pzWN5AAAED/FvIAs3LlSi1ZskQ///nP1dzcLI/Ho3/913/V0qVL7T733nuv2tvbNW/ePLW2tmrq1KnauHGjYmNj7T5r165VXl6epk2bpsjISGVmZmrFihWhLhcAABgo5PeB6Su4D0zv4h4XwLfjOQKcmbDdBwYAAKC3EWAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMbplQDz+eef68c//rFGjhypIUOGaMKECdq+fbvdblmWli5dqtGjR2vIkCFKS0vT3r17gx6jpaVFWVlZcjgciouLU05Ojtra2nqjXAAAYJiQB5gvvvhCU6ZM0eDBg/XWW29p9+7d+tWvfqURI0bYfYqLi7VixQqVlpaqpqZGQ4cOVXp6ug4fPmz3ycrK0q5du1RRUaHy8nJVVVVp3rx5oS4XAAAYKCrUD7h8+XIlJibqxRdftLclJyfb/21Zlp5++mndf//9uummmyRJ//Ef/yGXy6X169drzpw52rNnjzZu3Kja2lqlpKRIklauXKnrr79eTzzxhDweT6jLBgAABgn5DMwbb7yhlJQU/fCHP1RCQoIuu+wyPf/883b7vn375PP5lJaWZm9zOp1KTU1VdXW1JKm6ulpxcXF2eJGktLQ0RUZGqqam5qTH7ejoUCAQCFoAAED/FPIA86c//UmrVq3ShRdeqLffflt33nmn7rrrLq1Zs0aS5PP5JEkulytoP5fLZbf5fD4lJCQEtUdFRSk+Pt7uc7yioiI5nU57SUxMDPWpAQCAPiLkAaa7u1uXX365HnvsMV122WWaN2+e7rjjDpWWlob6UEEKCwvl9/vt5cCBA716PAAAED4hDzCjR4/W+PHjg7aNGzdOjY2NkiS32y1JampqCurT1NRkt7ndbjU3Nwe1HzlyRC0tLXaf48XExMjhcAQtAACgfwp5gJkyZYoaGhqCtn366acaM2aMpK8u6HW73aqsrLTbA4GAampq5PV6JUler1etra2qq6uz+2zatEnd3d1KTU0NdckAAMAwIf8W0sKFC3XVVVfpscce0y233KJt27Zp9erVWr16tSQpIiJCCxYs0COPPKILL7xQycnJWrJkiTwej2bNmiXpqxmbGTNm2B89dXV1KS8vT3PmzOEbSAAAIPQBZvLkyVq3bp0KCwv10EMPKTk5WU8//bSysrLsPvfee6/a29s1b948tba2aurUqdq4caNiY2PtPmvXrlVeXp6mTZumyMhIZWZmasWKFaEuFwAAGCjCsiwr3EX0hkAgIKfTKb/fz/UwveCCgjeD1v+8LCNMlQB9E88R4Myc7vs3v4UEAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIzT6wFm2bJlioiI0IIFC+xthw8fVm5urkaOHKlhw4YpMzNTTU1NQfs1NjYqIyND5513nhISErRo0SIdOXKkt8sFAAAG6NUAU1tbq1//+tf67ne/G7R94cKF2rBhg1577TVt2bJFBw8e1OzZs+32o0ePKiMjQ52dnfrggw+0Zs0alZWVaenSpb1ZLgAAMESvBZi2tjZlZWXp+eef14gRI+ztfr9fL7zwgp588kl9//vf16RJk/Tiiy/qgw8+0NatWyVJ77zzjnbv3q2XXnpJl156qa677jo9/PDDKikpUWdnZ2+VDAAADNFrASY3N1cZGRlKS0sL2l5XV6eurq6g7WPHjlVSUpKqq6slSdXV1ZowYYJcLpfdJz09XYFAQLt27Trp8To6OhQIBIIWAADQP0X1xoO+8sor2rFjh2pra09o8/l8io6OVlxcXNB2l8sln89n9/l6eDnWfqztZIqKivTggw+GoHoAANDXhTzAHDhwQHfffbcqKioUGxsb6of/RoWFhcrPz7fXA4GAEhMTz9nxAeDbXFDwpv3ff16WEcZKgP4h5B8h1dXVqbm5WZdffrmioqIUFRWlLVu2aMWKFYqKipLL5VJnZ6daW1uD9mtqapLb7ZYkud3uE76VdGz9WJ/jxcTEyOFwBC0AAKB/CnmAmTZtmj766CPV19fbS0pKirKysuz/Hjx4sCorK+19Ghoa1NjYKK/XK0nyer366KOP1NzcbPepqKiQw+HQ+PHjQ10yAAAwTMg/Qho+fLguueSSoG1Dhw7VyJEj7e05OTnKz89XfHy8HA6H5s+fL6/XqyuvvFKSNH36dI0fP15z585VcXGxfD6f7r//fuXm5iomJibUJQMAAMP0ykW8p/LUU08pMjJSmZmZ6ujoUHp6up577jm7fdCgQSovL9edd94pr9eroUOHKjs7Ww899FA4ygUAAH3MOQkwmzdvDlqPjY1VSUmJSkpKvnGfMWPG6He/+10vVwYAAEzEbyEBAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDhh+TFH9D8XFLwZtP7nZRlhqgR9AX8PAHobMzAAAMA4BBgAAGAcPkICAPQbfHw5cDADAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGCcqHAXgIGHn7sHAJwtZmAAAIBxmIEBAOAcYyb67IV8BqaoqEiTJ0/W8OHDlZCQoFmzZqmhoSGoz+HDh5Wbm6uRI0dq2LBhyszMVFNTU1CfxsZGZWRk6LzzzlNCQoIWLVqkI0eOhLpcnAMXFLwZtAwEA/GcAeBcCnmA2bJli3Jzc7V161ZVVFSoq6tL06dPV3t7u91n4cKF2rBhg1577TVt2bJFBw8e1OzZs+32o0ePKiMjQ52dnfrggw+0Zs0alZWVaenSpaEuFwAAGCjkHyFt3LgxaL2srEwJCQmqq6vTNddcI7/frxdeeEEvv/yyvv/970uSXnzxRY0bN05bt27VlVdeqXfeeUe7d+/Wu+++K5fLpUsvvVQPP/ywFi9erAceeEDR0dGhLhsAABik1y/i9fv9kqT4+HhJUl1dnbq6upSWlmb3GTt2rJKSklRdXS1Jqq6u1oQJE+Ryuew+6enpCgQC2rVr10mP09HRoUAgELQAAID+qVcDTHd3txYsWKApU6bokksukST5fD5FR0crLi4uqK/L5ZLP57P7fD28HGs/1nYyRUVFcjqd9pKYmBjiswEAAH1FrwaY3Nxcffzxx3rllVd68zCSpMLCQvn9fns5cOBArx8TAACER699jTovL0/l5eWqqqrS+eefb293u93q7OxUa2tr0CxMU1OT3G633Wfbtm1Bj3fsW0rH+hwvJiZGMTExIT4LAADQF4U8wFiWpfnz52vdunXavHmzkpOTg9onTZqkwYMHq7KyUpmZmZKkhoYGNTY2yuv1SpK8Xq8effRRNTc3KyEhQZJUUVEhh8Oh8ePHh7pkoMdMvYeDqXUDwPFCHmByc3P18ssv67e//a2GDx9uX7PidDo1ZMgQOZ1O5eTkKD8/X/Hx8XI4HJo/f768Xq+uvPJKSdL06dM1fvx4zZ07V8XFxfL5fLr//vuVm5vLLAsAAAh9gFm1apUk6Xvf+17Q9hdffFH/8i//Ikl66qmnFBkZqczMTHV0dCg9PV3PPfec3XfQoEEqLy/XnXfeKa/Xq6FDhyo7O1sPPfRQqMsFAAAG6pWPkE4lNjZWJSUlKikp+cY+Y8aM0e9+97tQlgYAAPoJfgsJANBvcd1X/0WAQb/29RcvXrgAoP/o9TvxAgAAhBozMDgt/KIyAKAvIcAg7PiMGgDQU3yEBAAAjMMMDHpFqD5yYnYGAHAyzMAAAADjMAMDAIDBBupMNTMwAADAOMzAAJAU3n/FccNBAD1FgBnABuq0IwAMJP31HwgEGAAnRcAF0JcRYMLgbNLwQH9TGejnDwD4ChfxAgAA4zADA6DXMXMGINQIMAMIP8gIYKA7VZjuyUf8AzGY96ULggkwhutLf0wAALOZFMoIMACAPqWnb6LMLg9MXMQLAACMQ4ABAADG4SMkAICks/vopi9fK4H+iQDTj/A5MAYCky4yBNB7CDAAAIQA4frcIsAAAHAamOXuW7iIFwAAGIcZGNhMvCCPKdv+j3/19gzPCQwUBBgAQJ9GKMPJEGCAfuxUsxfMbvQNprxBn83fiynnCHMQYID/39m8wPb0hb23Pq4jkAQbCG+a/eX/eX85D5w7BJgQONUT79teNAfCCyzQmwbCcyhcb+4DIVQMhHPsrwgwOKlwPql5QcHZ4O/n2zE+544JX4ww+e+hTweYkpISPf744/L5fJo4caJWrlypK664ItxlwVDh/Jd6T14k+uqMQl+tqyfOZrb0XNZh6rHO1XHP1TmF8jg9vR6tJzP3PW3vib4ccPpsgHn11VeVn5+v0tJSpaam6umnn1Z6eroaGhqUkJAQ7vLO6g2pt46D/vGiearj9pXg0Ft19aXZv3CNNc97HI+/iRNFWJZlhbuIk0lNTdXkyZP17LPPSpK6u7uVmJio+fPnq6Cg4JT7BwIBOZ1O+f1+ORyOkNfXW39Mx79g8kcLU3z9b7c//t32NMz0xzEIJV7rzNdbAf9037/75AxMZ2en6urqVFhYaG+LjIxUWlqaqqurT7pPR0eHOjo67HW/3y/pq4HoDd0dX/bK4x5fb28dBwi1pIWvhbuEXnX8+X38YPq39ue5++36+9/LQNBb76/HHvdU8yt9MsD87W9/09GjR+VyuYK2u1wuffLJJyfdp6ioSA8++OAJ2xMTE3ulxt7ifDrcFQA4HTxXMdD19nPg0KFDcjqd39jeJwPMmSgsLFR+fr693t3drZaWFo0cOVIREREhPVYgEFBiYqIOHDjQKx9P9TeMV88wXj3HmPUM49VzjFnPnM14WZalQ4cOyePxfGu/PhlgRo0apUGDBqmpqSloe1NTk9xu90n3iYmJUUxMTNC2uLi43ipRkuRwOPhD7gHGq2cYr55jzHqG8eo5xqxnznS8vm3m5Zg++WvU0dHRmjRpkiorK+1t3d3dqqyslNfrDWNlAACgL+iTMzCSlJ+fr+zsbKWkpOiKK67Q008/rfb2dv3kJz8Jd2kAACDM+myA+dGPfqS//vWvWrp0qXw+ny699FJt3LjxhAt7wyEmJka//OUvT/jICifHePUM49VzjFnPMF49x5j1zLkYrz57HxgAAIBv0ievgQEAAPg2BBgAAGAcAgwAADAOAQYAABiHANNDJSUluuCCCxQbG6vU1FRt27Yt3CX1CUVFRZo8ebKGDx+uhIQEzZo1Sw0NDUF9Dh8+rNzcXI0cOVLDhg1TZmbmCTcrHKiWLVumiIgILViwwN7GeJ3o888/149//GONHDlSQ4YM0YQJE7R9+3a73bIsLV26VKNHj9aQIUOUlpamvXv3hrHi8Dl69KiWLFmi5ORkDRkyRN/5znf08MMPB/2+zEAfr6qqKs2cOVMej0cRERFav359UPvpjE9LS4uysrLkcDgUFxennJwctbW1ncOzOHe+bby6urq0ePFiTZgwQUOHDpXH49Htt9+ugwcPBj1GKMeLANMDr776qvLz8/XLX/5SO3bs0MSJE5Wenq7m5uZwlxZ2W7ZsUW5urrZu3aqKigp1dXVp+vTpam9vt/ssXLhQGzZs0GuvvaYtW7bo4MGDmj17dhir7htqa2v161//Wt/97neDtjNewb744gtNmTJFgwcP1ltvvaXdu3frV7/6lUaMGGH3KS4u1ooVK1RaWqqamhoNHTpU6enpOnz4cBgrD4/ly5dr1apVevbZZ7Vnzx4tX75cxcXFWrlypd1noI9Xe3u7Jk6cqJKSkpO2n874ZGVladeuXaqoqFB5ebmqqqo0b968c3UK59S3jdeXX36pHTt2aMmSJdqxY4def/11NTQ06MYbbwzqF9LxsnDarrjiCis3N9deP3r0qOXxeKyioqIwVtU3NTc3W5KsLVu2WJZlWa2trdbgwYOt1157ze6zZ88eS5JVXV0drjLD7tChQ9aFF15oVVRUWP/v//0/6+6777Ysi/E6mcWLF1tTp079xvbu7m7L7XZbjz/+uL2ttbXViomJsf7rv/7rXJTYp2RkZFg//elPg7bNnj3bysrKsiyL8TqeJGvdunX2+umMz+7duy1JVm1trd3nrbfesiIiIqzPP//8nNUeDseP18ls27bNkmTt37/fsqzQjxczMKeps7NTdXV1SktLs7dFRkYqLS1N1dXVYaysb/L7/ZKk+Ph4SVJdXZ26urqCxm/s2LFKSkoa0OOXm5urjIyMoHGRGK+TeeONN5SSkqIf/vCHSkhI0GWXXabnn3/ebt+3b598Pl/QmDmdTqWmpg7IMbvqqqtUWVmpTz/9VJL0hz/8Qe+//76uu+46SYzXqZzO+FRXVysuLk4pKSl2n7S0NEVGRqqmpuac19zX+P1+RURE2L9LGOrx6rN34u1r/va3v+no0aMn3AnY5XLpk08+CVNVfVN3d7cWLFigKVOm6JJLLpEk+Xw+RUdHn/ADmy6XSz6fLwxVht8rr7yiHTt2qLa29oQ2xutEf/rTn7Rq1Srl5+fr3/7t31RbW6u77rpL0dHRys7OtsflZM/RgThmBQUFCgQCGjt2rAYNGqSjR4/q0UcfVVZWliQxXqdwOuPj8/mUkJAQ1B4VFaX4+PgBP4aHDx/W4sWLdeutt9o/5hjq8SLAIORyc3P18ccf6/333w93KX3WgQMHdPfdd6uiokKxsbHhLscI3d3dSklJ0WOPPSZJuuyyy/Txxx+rtLRU2dnZYa6u7/nNb36jtWvX6uWXX9bFF1+s+vp6LViwQB6Ph/FCr+rq6tItt9wiy7K0atWqXjsOHyGdplGjRmnQoEEnfAukqalJbrc7TFX1PXl5eSovL9d7772n888/397udrvV2dmp1tbWoP4Ddfzq6urU3Nysyy+/XFFRUYqKitKWLVu0YsUKRUVFyeVyMV7HGT16tMaPHx+0bdy4cWpsbJQke1x4jn5l0aJFKigo0Jw5czRhwgTNnTtXCxcuVFFRkSTG61ROZ3zcbvcJX+I4cuSIWlpaBuwYHgsv+/fvV0VFhT37IoV+vAgwpyk6OlqTJk1SZWWlva27u1uVlZXyer1hrKxvsCxLeXl5WrdunTZt2qTk5OSg9kmTJmnw4MFB49fQ0KDGxsYBOX7Tpk3TRx99pPr6entJSUlRVlaW/d+MV7ApU6ac8NX8Tz/9VGPGjJEkJScny+12B41ZIBBQTU3NgByzL7/8UpGRwS/xgwYNUnd3tyTG61ROZ3y8Xq9aW1tVV1dn99m0aZO6u7uVmpp6zmsOt2PhZe/evXr33Xc1cuTIoPaQj1ePL/sdwF555RUrJibGKisrs3bv3m3NmzfPiouLs3w+X7hLC7s777zTcjqd1ubNm62//OUv9vLll1/afX72s59ZSUlJ1qZNm6zt27dbXq/X8nq9Yay6b/n6t5Asi/E63rZt26yoqCjr0Ucftfbu3WutXbvWOu+886yXXnrJ7rNs2TIrLi7O+u1vf2vt3LnTuummm6zk5GTr73//exgrD4/s7GzrH//xH63y8nJr37591uuvv26NGjXKuvfee+0+A328Dh06ZH344YfWhx9+aEmynnzySevDDz+0vzVzOuMzY8YM67LLLrNqamqs999/37rwwgutW2+9NVyn1Ku+bbw6OzutG2+80Tr//POt+vr6oPeBjo4O+zFCOV4EmB5auXKllZSUZEVHR1tXXHGFtXXr1nCX1CdIOuny4osv2n3+/ve/Wz//+c+tESNGWOedd5518803W3/5y1/CV3Qfc3yAYbxOtGHDBuuSSy6xYmJirLFjx1qrV68Oau/u7raWLFliuVwuKyYmxpo2bZrV0NAQpmrDKxAIWHfffbeVlJRkxcbGWv/0T/9k3XfffUFvJgN9vN57772Tvm5lZ2dblnV64/N///d/1q233moNGzbMcjgc1k9+8hPr0KFDYTib3vdt47Vv375vfB9477337McI5XhFWNbXbssIAABgAK6BAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4/x/GmgRdWXo7owAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('trains.json', 'r',encoding='utf-8') as f:\n",
    "    trains = json.load(f)\n",
    "\n",
    "labels = []\n",
    "sents = []\n",
    "for sent in trains:\n",
    "    labels.append(int(sent['label']))\n",
    "    sents.append(sent['sentence'])\n",
    " \n",
    "print(f'类别：{sorted(set(labels))}')\n",
    "print(f'训练集的数据量：{len(labels)}')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(np.array(labels),bins=119)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb2abda",
   "metadata": {},
   "source": [
    "共有119个类：0-118，类别分布不均匀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60ea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a9fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09fb7a20",
   "metadata": {},
   "source": [
    "# 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48118af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f60c3dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trains.json', 'r',encoding='utf-8') as f:\n",
    "    trains = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4374e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate = train_test_split(trains, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a5f988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/trains.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(X_train, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37fba252",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/validates.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(X_validate, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49121ca",
   "metadata": {},
   "source": [
    "119个类别:0-118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e447478d",
   "metadata": {},
   "source": [
    "# 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9de3d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import json\n",
    "\n",
    "with open('trains.json', 'r',encoding='utf-8') as f:\n",
    "    trains = json.load(f)\n",
    "    \n",
    "trains_data = [] #[[第一个句子的分词结果],[第二个句子的分词结果],...]\n",
    "for sent in trains:\n",
    "    fenci = jieba.cut(sent['sentence'],cut_all=False)\n",
    "    res=[]\n",
    "    for j in fenci:\n",
    "        res.append(j)\n",
    "    trains_data.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09d80ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336.0\n",
      "489.0100000000002\n"
     ]
    }
   ],
   "source": [
    "sents_len = []\n",
    "for sent in trains_data:\n",
    "    sents_len.append(len(sent))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(np.array(sents_len),bins=20)\n",
    "plt.show() #大部分句子长度小于500\n",
    "\n",
    "print(np.percentile(sents_len, 95))\n",
    "print(np.percentile(sents_len, 99))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aec3b7",
   "metadata": {},
   "source": [
    "## 只获取前512个词的分词完整代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b6dccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import json\n",
    "\n",
    "# 10000条训练数据\n",
    "with open('trains.json', 'r',encoding='utf-8') as f:\n",
    "    trains = json.load(f)\n",
    "\n",
    "train_data = [] #[[第一个句子的分词结果],[第二个句子的分词结果],...]\n",
    "for sent in trains:\n",
    "    sentence = sent['sentence'] if len(sent['sentence'])<=512 else sent['sentence'][:512]  #保证句子长度小于等于512\n",
    "    fenci = jieba.cut(sentence,cut_all=False)\n",
    "    res=[]\n",
    "    for j in fenci:\n",
    "        res.append(j)\n",
    "    train_data.append(res)\n",
    "\n",
    "\n",
    "# 1425条测试数据\n",
    "with open('tests.json', 'r',encoding='utf-8') as f:\n",
    "    tests = json.load(f)\n",
    "\n",
    "test_data = [] #[[第一个句子的分词结果],[第二个句子的分词结果],...]\n",
    "for sent in tests:\n",
    "    sentence = sent['sentence'] if len(sent['sentence'])<=512 else sent['sentence'][:512]\n",
    "    fenci = jieba.cut(sentence,cut_all=False)\n",
    "    res=[]\n",
    "    for j in fenci:\n",
    "        res.append(j)\n",
    "    test_data.append(res)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c819d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd24d8a5",
   "metadata": {},
   "source": [
    "# 建立词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cd9710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vocab import Vocab\n",
    "vocab = Vocab.build(train_data+test_data)\n",
    "for i,sent in enumerate(trains):\n",
    "    train_data[i] = (vocab.convert_tokens_to_ids(train_data[i]), int(sent['label']))\n",
    "\n",
    "for i,sent in enumerate(tests):\n",
    "    test_data[i] = (vocab.convert_tokens_to_ids(test_data[i]), int(sent['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "131321a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72587"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.token_to_idx) #词表的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9b75c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 2, 3, 13, 14, 15, 16, 17, 18, 19, 5, 6, 7, 20, 21, 22, 23, 24, 25, 26, 13, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 13, 38, 39, 40, 41, 42, 11, 43, 44, 45, 46, 47, 48, 49, 12, 50, 51, 52, 13, 53, 35, 50, 54, 55, 56, 57, 58, 12, 7, 20, 22, 40, 59, 12, 60, 47, 61, 62, 59, 63, 64, 65, 66, 13, 67, 47, 68, 69, 70, 71, 22, 72, 50, 35, 47, 49, 73, 13, 11, 74, 75, 15, 40, 65, 76, 40, 65, 77, 40, 58, 78, 49, 79, 13, 80, 81, 39, 82, 77, 83, 22, 84, 85, 86, 13, 11, 87, 88, 89, 90, 91, 92, 93, 3, 22, 94, 40, 95, 96, 97, 98, 12, 99, 22, 50, 49, 13, 100, 29, 44, 101, 102, 90, 103, 104, 50, 35, 4, 7, 53, 35, 54, 55, 7, 20, 51, 105, 106, 107, 13, 108, 109, 40, 110, 111, 112, 49, 79, 15, 40, 65, 76, 40, 65, 113, 40, 114, 115, 49, 79, 116, 117, 41, 118, 13, 11, 119, 120, 4, 15, 121, 119, 122, 15, 123, 124, 11, 13, 125, 126, 121, 127, 13, 128, 82, 7, 20, 62, 129, 130, 131, 132, 133, 12, 119, 39, 62, 13, 129, 13, 134, 135, 63, 136, 62, 13, 61, 59, 137, 138, 139, 140, 141, 140, 142, 63, 143, 144, 11, 145, 146, 147, 148, 149, 141, 140, 142, 150, 34, 35, 36, 37, 13, 38, 39, 40, 41, 151, 150, 152, 65, 153, 154, 155, 156, 157, 103, 158, 159, 65, 51, 160, 153, 161], 11)\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede08cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run utils.py\n",
    "# train_data, test_data, vocab = load_sentence()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805159da",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859369f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cd9b5b7",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "847f0085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eff6cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BowDataset(Dataset):\n",
    "    def __init__(self, data): #data为原始的数据\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "002ef52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run utils.py\n",
    "#train_data, test_data, vocab = load_sentence()\n",
    "train_dataset = BowDataset(train_data) #BowDataset是Dataset的子类\n",
    "test_dataset = BowDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3656d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    # 从独立样本集合中构建各批次的输入输出\n",
    "    # 其中，BowDatasete类定义了一个样本的数据结构，即输入标签和输出标签的元组\n",
    "    # 因此，将输入inputs定义为一个张量的列表，其中每个张量为原始句子中标记序列对应的索引值序列ex[0]\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    # 输出目标targets为该批次中全部样例输出结果（0或1）构成的张量\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    offsets = [0] + [i.shape[0] for i in inputs]\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)  #获取一个批次中每个序列的偏移量\n",
    "    inputs = torch.cat(inputs)\n",
    "    return inputs, offsets, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05d3cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa9d0a",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc110e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(MLP, self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.activate = F.relu\n",
    "        self.linear2 = nn.Linear(hidden_dim, num_class)\n",
    "    def forward(self, inputs, offsets):\n",
    "        embedding = self.embedding(inputs, offsets)\n",
    "        hidden = self.activate(self.linear1(embedding))\n",
    "        outputs = self.linear2(hidden)\n",
    "        log_probs = F.log_softmax(outputs, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd4de6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (embedding): EmbeddingBag(72587, 128, mode=mean)\n",
       "  (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (linear2): Linear(in_features=256, out_features=119, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import *\n",
    "\n",
    "# 超参数设置\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 119\n",
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "\n",
    "# 加载模型\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = MLP(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) # 将模型加载到CPU或GPU设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdf99f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:29<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1166.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:24<00:00, 13.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 892.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:24<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 713.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:24<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 582.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:24<00:00, 12.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 476.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "        #inputs, offsets, targets = [x for x in batch]\n",
    "        log_probs = model(inputs, offsets)\n",
    "        #print(log_probs)\n",
    "        #print(targets)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "043155a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1425/1425 [00:02<00:00, 635.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.46\n",
      "f1_macro:0.22\n",
      "f1_weighted:0.43\n",
      "f1_macro:0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "# 测试过程\n",
    "acc = 0\n",
    "y_pred = np.array([]).astype(int)  #存储真实的target\n",
    "y_true = np.array([]).astype(int)  #存储预测出来的target\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, offsets, targets = [x.to(device) for x in batch]\n",
    "    #inputs, offsets, targets = [x for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, offsets)\n",
    "        y_pred = np.append(y_pred,output.argmax(dim=1).cpu().numpy()) #要先把数据放在cpu上，才能转成numpy\n",
    "        y_true = np.append(y_true,targets.cpu().numpy())\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "# 输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")\n",
    "print(f\"f1_macro:{f1_score(y_true,y_pred,average='macro'):.2f}\")\n",
    "print(f\"f1_weighted:{f1_score(y_true,y_pred,average='weighted'):.2f}\")\n",
    "print(f\"f1_macro:{f1_score(y_true,y_pred,average='macro'):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc5f47",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1866f",
   "metadata": {},
   "source": [
    "## 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff0143ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e497035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "236add1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "#%run utils.py\n",
    "#train_data, test_data, vocab = load_sentence() #MLP模型已经运行过了\n",
    "train_dataset = CnnDataset(train_data)\n",
    "test_dataset = CnnDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da480c65",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9a2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tqdm是一个Pyth模块，能以进度条的方式显示迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#超参数设置\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 119\n",
    "batch_size = 32\n",
    "num_epoch = 5\n",
    "filter_size = 3\n",
    "num_filter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7781957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, filter_size, num_filter, num_class):\n",
    "        super(CNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.conv1d = nn.Conv1d(embedding_dim, num_filter, filter_size, padding=1)\n",
    "        self.activate = F.relu\n",
    "        self.linear = nn.Linear(num_filter, num_class)\n",
    "    def forward(self, inputs):\n",
    "        embedding = self.embedding(inputs)\n",
    "        convolution = self.activate(self.conv1d(embedding.permute(0, 2, 1))) #permute维度交换\n",
    "        pooling = F.max_pool1d(convolution, kernel_size=convolution.shape[2])\n",
    "        outputs = self.linear(pooling.squeeze(dim=2))\n",
    "        log_probs = F.log_softmax(outputs, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3b3aa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(75040, 128)\n",
       "  (conv1d): Conv1d(128, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (linear): Linear(in_features=100, out_features=119, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN(len(vocab), embedding_dim, filter_size, num_filter, num_class)\n",
    "model.to(device) #将模型加载到CPU或GPU设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53fff6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 0: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:45<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1159.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:35<00:00,  8.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 904.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:31<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 736.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:31<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 598.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████████████████████████████████████████████████████████| 313/313 [00:31<00:00, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 471.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, targets = [x.to(device) for x in batch]\n",
    "        #inputs, targets = [x for x in batch]\n",
    "        log_probs = model(inputs)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "146dca47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████████████████████████████████████| 1425/1425 [00:02<00:00, 579.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#测试过程\n",
    "import numpy as np\n",
    "acc = 0\n",
    "y_pred = np.array([]).astype(int)  #存储真实的target\n",
    "y_true = np.array([]).astype(int)  #存储预测出来的target\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, targets = [x.to(device) for x in batch]\n",
    "    #inputs, targets = [x for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs)\n",
    "        y_pred = np.append(y_pred,output.argmax(dim=1).cpu().numpy()) #要先把数据放在cpu上，才能转成numpy\n",
    "        y_true = np.append(y_true,targets.cpu().numpy())\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "#输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56c25f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbb767c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18784838652529542"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。\n",
    "# 该方法能够平等看待每个类别，但是它的值会受稀有类别影响。\n",
    "f1_score(y_true,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6f9cc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40249235248216314"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。\n",
    "# 该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。\n",
    "f1_score(y_true,y_pred,average='weighted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35603b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4357894736842105"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。\n",
    "f1_score(y_true,y_pred,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc35a13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b02f4c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as plt\n",
    "plt.figure(1)\n",
    "plt.hist(y_true,bins=119)\n",
    "plt.show() #可以看到类别分布很不均匀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b869147",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a431ad35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:48:20.625524400Z",
     "start_time": "2023-10-20T02:48:18.225166400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence\n",
    "\n",
    "#tqdm是一个Python模块，能以进度条的方式显式迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class LstmDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    # 获得每个序列的长度\n",
    "    lengths = torch.tensor([len(ex[0]) for ex in examples])\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, lengths, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2be8b88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:48:47.108957700Z",
     "start_time": "2023-10-20T02:48:28.341177200Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#加载数据\n",
    "\n",
    "#train_data, test_data, vocab = load_sentence()\n",
    "train_dataset = LstmDataset(train_data)\n",
    "test_dataset = LstmDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a85ecbee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:48:52.418325700Z",
     "start_time": "2023-10-20T02:48:52.387079200Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        embeddings = self.embeddings(inputs)\n",
    "        # pack_padded_sequence函数将变长序列打包\n",
    "        # lengths.cpu()注意这里改为cpu，pytorch自身的问题\n",
    "        x_pack = pack_padded_sequence(embeddings, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        hidden, (hn, cn) = self.lstm(x_pack)\n",
    "        outputs = self.output(hn[-1])\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7877866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:57:30.977120300Z",
     "start_time": "2023-10-20T02:56:39.530838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394c86be05494189ad4eed8b407505ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 0:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1246.79\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_class = 119\n",
    "batch_size = 32\n",
    "num_epoch = 1 #5\n",
    "#加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTM(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) #将模型加载到GPU中\n",
    "\n",
    "#训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "        log_probs = model(inputs, lengths)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46f93b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T02:56:18.237270400Z",
     "start_time": "2023-10-20T02:55:55.682785900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35639566922472ea2c1cb5899fca333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/1425 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.16\n",
      "f1_macro:0.00\n",
      "f1_weighted:0.05\n",
      "f1_macro:0.00\n"
     ]
    }
   ],
   "source": [
    "#测试过程\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "acc = 0\n",
    "y_pred = np.array([]).astype(int)  #存储真实的target\n",
    "y_true = np.array([]).astype(int)  #存储预测出来的target\n",
    "for batch in tqdm(test_data_loader, desc=f\"Testing\"):\n",
    "    inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "    #inputs, lengths, targets = [x for x in batch]\n",
    "    with torch.no_grad():\n",
    "        output = model(inputs, lengths)\n",
    "        y_pred = np.append(y_pred,output.argmax(dim=1).cpu().numpy()) #要先把数据放在cpu上，才能转成numpy\n",
    "        y_true = np.append(y_true,targets.cpu().numpy())\n",
    "        acc += (output.argmax(dim=1) == targets).sum().item()\n",
    "\n",
    "#输出在测试集上的准确率\n",
    "print(f\"Acc: {acc / len(test_data_loader):.2f}\")\n",
    "print(f\"f1_macro:{f1_score(y_true,y_pred,average='macro'):.2f}\")\n",
    "print(f\"f1_weighted:{f1_score(y_true,y_pred,average='weighted'):.2f}\")\n",
    "print(f\"f1_macro:{f1_score(y_true,y_pred,average='macro'):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d746940ed53bf",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b35b510cbc5fcf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:26:30.658513400Z",
     "start_time": "2023-10-20T03:26:10.098733800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ASUS\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.653 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from collections import defaultdict\n",
    "from vocab import Vocab\n",
    "from utils import load_sentence, length_to_mask\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# tqdm是一个Pyth模块，能以进度条的方式显式迭代的进度\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "\n",
    "def collate_fn(examples):\n",
    "    lengths = torch.tensor([len(ex[0]) for ex in examples])\n",
    "    inputs = [torch.tensor(ex[0]) for ex in examples]\n",
    "    targets = torch.tensor([ex[1] for ex in examples], dtype=torch.long)\n",
    "    # 对batch内的样本进行padding，使其具有相同长度\n",
    "    inputs = pad_sequence(inputs, batch_first=True)\n",
    "    return inputs, lengths, targets\n",
    "\n",
    "batch_size = 32\n",
    "# 加载数据\n",
    "train_data, test_data, vocab = load_sentence()\n",
    "train_dataset = TransformerDataset(train_data)\n",
    "test_dataset = TransformerDataset(test_data)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9db5b7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 483])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_data_loader)\n",
    "a = dataiter.next()\n",
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74526f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # 对偶数位置编码\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # 对奇数位置编码\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # pe是一个tensor对象，它被注册为模型的缓冲区，并且被命名为pe。这意味着在模型中可以通过self.pe来访问和使用这个缓冲区。缓冲区是一种特殊的tensor，它可以与模型的参数一起保存和加载，并且在模型的前向传播过程中不会被更新。即不对位置编码层求梯度。\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :] #输入的词向量与位置编码相加\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb48cdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1, 128])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positionEncoding = PositionalEncoding(128,0.1,512)\n",
    "positionEncoding.pe.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a3749da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([342, 1, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positionEncoding.pe[:342,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbed65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a56ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b5486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad1571fc7b718d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:29:31.067681700Z",
     "start_time": "2023-10-20T03:29:29.990459500Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # 对偶数位置编码\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # 对奇数位置编码\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # pe是一个tensor对象，它被注册为模型的缓冲区，并且被命名为pe。这意味着在模型中可以通过self.pe来访问和使用这个缓冲区。缓冲区是一种特殊的tensor，它可以与模型的参数一起保存和加载，并且在模型的前向传播过程中不会被更新。即不对位置编码层求梯度。\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        #print(self.pe.size())\n",
    "        #print(self.pe[:x.size(0), :].size())\n",
    "        x = x + self.pe[:x.size(0), :] #输入的词向量与位置编码相加\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class,\n",
    "                 dim_feedforward=512, num_head=2, num_layers=2, dropout=0.1, max_len=3268, activation: str = \"relu\"):\n",
    "        super(Transformer, self).__init__()\n",
    "        # 词嵌入层\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding = PositionalEncoding(embedding_dim, dropout, max_len)\n",
    "        # 编码层：使用TransformerEncoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_head, dim_feedforward, dropout, activation)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        # 输出层\n",
    "        self.output = nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "\n",
    "    def forward(self, inputs, lengths):\n",
    "        #与LSTM处理情况一样，输入数据的第1维是批次，需要转换为TransformerEncoder，所需的第1维是长度，第2维是批次的形状\n",
    "        inputs = torch.transpose(inputs, 0, 1)\n",
    "        hidden_states = self.embeddings(inputs)\n",
    "        hidden_states = self.position_embedding(hidden_states) \n",
    "        attention_mask = length_to_mask(lengths) == False  #根据批次中每个序列的长度生成Mask矩阵\n",
    "        hidden_states = self.transformer(hidden_states, src_key_padding_mask=attention_mask)\n",
    "        hidden_states = hidden_states[0, :, :] #第一个隐含层（代表整个序列）\n",
    "        output = self.output(hidden_states)#取第一个标记的输出结果作为分类层的输入\n",
    "        log_probs = F.log_softmax(output, dim=1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ca09629589875b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-20T03:31:04.888454800Z",
     "start_time": "2023-10-20T03:31:04.616134300Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 2.00 GiB total capacity; 863.74 MiB already allocated; 13.06 MiB free; 894.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m Transformer(\u001b[38;5;28mlen\u001b[39m(vocab), embedding_dim, hidden_dim, num_class)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 将模型加载到GPU中（如果已经正确安装）\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 训练过程\u001b[39;00m\n\u001b[0;32m     14\u001b[0m nll_loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:612\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m--> 612\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:359\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 359\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    363\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    364\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    370\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:381\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 381\u001b[0m         param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mD:\\Anaconda3\\envs\\pytorch1.7.1\\lib\\site-packages\\torch\\nn\\modules\\module.py:610\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 38.00 MiB (GPU 0; 2.00 GiB total capacity; 863.74 MiB already allocated; 13.06 MiB free; 894.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "import torch, gc\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "num_class = 119\n",
    "batch_size = 1 #32\n",
    "num_epoch = 1\n",
    "\n",
    "# 加载模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(len(vocab), embedding_dim, hidden_dim, num_class)\n",
    "model.to(device) # 将模型加载到GPU中（如果已经正确安装）\n",
    "\n",
    "# 训练过程\n",
    "nll_loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # 使用Adam优化器\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_data_loader, desc=f\"Training Epoch {epoch}\"):\n",
    "        inputs, lengths, targets = [x.to(device) for x in batch]\n",
    "        #inputs, lengths, targets = [x for x in batch]\n",
    "        \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        log_probs = model(inputs, lengths)\n",
    "        loss = nll_loss(log_probs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Loss: {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492922c81a2f533a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.7.1",
   "language": "python",
   "name": "pytorch1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
